{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/codeclassifiers/video-game-sales-prediction-jupyter-notebook/blob/master/Video_Game_Sales_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "rLjXL6QNLljQ",
    "outputId": "23eab7ae-9b7b-4829-e5a9-94b2072af423"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jr6R9vJmOUKj"
   },
   "outputs": [],
   "source": [
    "# Read the csv files\n",
    "input = pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item code</th>\n",
       "      <th>Category</th>\n",
       "      <th>State</th>\n",
       "      <th>29-01-2017</th>\n",
       "      <th>30-01-2017</th>\n",
       "      <th>31-01-2017</th>\n",
       "      <th>01-02-2017</th>\n",
       "      <th>02-02-2017</th>\n",
       "      <th>03-02-2017</th>\n",
       "      <th>04-02-2017</th>\n",
       "      <th>...</th>\n",
       "      <th>13-02-2022</th>\n",
       "      <th>14-02-2022</th>\n",
       "      <th>15-02-2022</th>\n",
       "      <th>16-02-2022</th>\n",
       "      <th>17-02-2022</th>\n",
       "      <th>18-02-2022</th>\n",
       "      <th>19-02-2022</th>\n",
       "      <th>20-02-2022</th>\n",
       "      <th>21-02-2022</th>\n",
       "      <th>22-02-2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANTIDIABETIC_001</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANTIDIABETIC_002</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANTIDIABETIC_003</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANTIDIABETIC_004</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANTIDIABETIC_005</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>ANTIBIOTIC_215</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>ANTIBIOTIC_216</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>ANTIBIOTIC_217</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>ANTIBIOTIC_218</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>ANTIBIOTIC_219</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3492 rows × 1854 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Item code      Category State  29-01-2017  30-01-2017  \\\n",
       "0     ANTIDIABETIC_001  ANTIDIABETIC    MH           0           0   \n",
       "1     ANTIDIABETIC_002  ANTIDIABETIC    MH           0           0   \n",
       "2     ANTIDIABETIC_003  ANTIDIABETIC    MH           0           0   \n",
       "3     ANTIDIABETIC_004  ANTIDIABETIC    MH           0           0   \n",
       "4     ANTIDIABETIC_005  ANTIDIABETIC    MH           0           0   \n",
       "...                ...           ...   ...         ...         ...   \n",
       "3487    ANTIBIOTIC_215    ANTIBIOTIC    TN           0           0   \n",
       "3488    ANTIBIOTIC_216    ANTIBIOTIC    TN           0           0   \n",
       "3489    ANTIBIOTIC_217    ANTIBIOTIC    TN           0           0   \n",
       "3490    ANTIBIOTIC_218    ANTIBIOTIC    TN           6          11   \n",
       "3491    ANTIBIOTIC_219    ANTIBIOTIC    TN           5           3   \n",
       "\n",
       "      31-01-2017  01-02-2017  02-02-2017  03-02-2017  04-02-2017  ...  \\\n",
       "0              0           0           0           0           0  ...   \n",
       "1              0           0           0           0           0  ...   \n",
       "2              0           0           0           0           0  ...   \n",
       "3              0           0           0           0           0  ...   \n",
       "4              0           0           0           0           0  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "3487           0           0           0           0           0  ...   \n",
       "3488           0           0           0           1           0  ...   \n",
       "3489           0           1           0           2           1  ...   \n",
       "3490           5          10           0          17          13  ...   \n",
       "3491           2           5           0           1           2  ...   \n",
       "\n",
       "      13-02-2022  14-02-2022  15-02-2022  16-02-2022  17-02-2022  18-02-2022  \\\n",
       "0              4           0           0           0           0           1   \n",
       "1              0           0           0           1           0           0   \n",
       "2              1           0           0           0           1           0   \n",
       "3              2           1           0           0           0           2   \n",
       "4              5           2           2           2           1           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3487           1           3           0           1           1           0   \n",
       "3488           1           0           0           0           0           0   \n",
       "3489           3           2           0           1           1           1   \n",
       "3490           3          11          14          12          12           8   \n",
       "3491           3           3           4           8           4           2   \n",
       "\n",
       "      19-02-2022  20-02-2022  21-02-2022  22-02-2022  \n",
       "0              1           2           0           4  \n",
       "1              0           1           0           0  \n",
       "2              1           0           1           0  \n",
       "3              0           5           4           2  \n",
       "4              0           0           3           0  \n",
       "...          ...         ...         ...         ...  \n",
       "3487           0           2           1           1  \n",
       "3488           0           1           0           1  \n",
       "3489           2           6           1           0  \n",
       "3490           9          10          15           7  \n",
       "3491           1           3           2           1  \n",
       "\n",
       "[3492 rows x 1854 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long = pd.melt(input, id_vars =['Item code','Category', 'State'],var_name ='Date', value_name='Sales')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "pJmuzoXpeyYp",
    "outputId": "f48897ab-72f4-4089-d343-eb09adf05fe1"
   },
   "outputs": [],
   "source": [
    "#print all columns to understand the dataset\n",
    "train_data = data_long.drop(columns=['Sales'])  # Features\n",
    "train_labels = data_long['Sales']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item code</th>\n",
       "      <th>Category</th>\n",
       "      <th>State</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANTIDIABETIC_001</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>29-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANTIDIABETIC_002</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>29-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANTIDIABETIC_003</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>29-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANTIDIABETIC_004</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>29-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANTIDIABETIC_005</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>29-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463687</th>\n",
       "      <td>ANTIBIOTIC_215</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>22-02-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463688</th>\n",
       "      <td>ANTIBIOTIC_216</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>22-02-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463689</th>\n",
       "      <td>ANTIBIOTIC_217</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>22-02-2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463690</th>\n",
       "      <td>ANTIBIOTIC_218</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>22-02-2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463691</th>\n",
       "      <td>ANTIBIOTIC_219</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>22-02-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6463692 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Item code      Category State        Date  Sales\n",
       "0        ANTIDIABETIC_001  ANTIDIABETIC    MH  29-01-2017      0\n",
       "1        ANTIDIABETIC_002  ANTIDIABETIC    MH  29-01-2017      0\n",
       "2        ANTIDIABETIC_003  ANTIDIABETIC    MH  29-01-2017      0\n",
       "3        ANTIDIABETIC_004  ANTIDIABETIC    MH  29-01-2017      0\n",
       "4        ANTIDIABETIC_005  ANTIDIABETIC    MH  29-01-2017      0\n",
       "...                   ...           ...   ...         ...    ...\n",
       "6463687    ANTIBIOTIC_215    ANTIBIOTIC    TN  22-02-2022      1\n",
       "6463688    ANTIBIOTIC_216    ANTIBIOTIC    TN  22-02-2022      1\n",
       "6463689    ANTIBIOTIC_217    ANTIBIOTIC    TN  22-02-2022      0\n",
       "6463690    ANTIBIOTIC_218    ANTIBIOTIC    TN  22-02-2022      7\n",
       "6463691    ANTIBIOTIC_219    ANTIBIOTIC    TN  22-02-2022      1\n",
       "\n",
       "[6463692 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "train_data=data_long\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'], format='%d-%m-%Y')\n",
    "train_data['Item code'] = label_encoder.fit_transform(train_data['Item code'])\n",
    "train_data['Category'] = label_encoder.fit_transform(train_data['Category'])\n",
    "train_data['State'] = label_encoder.fit_transform(train_data['State'])\n",
    "# Fit and transform the 'Item code' column\n",
    "train_pool_encoded = Pool(data=train_data.drop(columns=['Sales']), label=train_data['Sales'])\n",
    "model = CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1, loss_function='RMSE', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3826047\ttotal: 446ms\tremaining: 3m 42s\n",
      "1:\tlearn: 2.3791198\ttotal: 918ms\tremaining: 3m 48s\n",
      "2:\tlearn: 2.3762229\ttotal: 1.38s\tremaining: 3m 48s\n",
      "3:\tlearn: 2.3737241\ttotal: 1.77s\tremaining: 3m 40s\n",
      "4:\tlearn: 2.3703154\ttotal: 2.2s\tremaining: 3m 38s\n",
      "5:\tlearn: 2.3684374\ttotal: 2.59s\tremaining: 3m 33s\n",
      "6:\tlearn: 2.3659017\ttotal: 3.02s\tremaining: 3m 32s\n",
      "7:\tlearn: 2.3638318\ttotal: 3.43s\tremaining: 3m 31s\n",
      "8:\tlearn: 2.3620222\ttotal: 3.83s\tremaining: 3m 29s\n",
      "9:\tlearn: 2.3605805\ttotal: 4.27s\tremaining: 3m 29s\n",
      "10:\tlearn: 2.3593026\ttotal: 4.66s\tremaining: 3m 27s\n",
      "11:\tlearn: 2.3582118\ttotal: 5.15s\tremaining: 3m 29s\n",
      "12:\tlearn: 2.3573237\ttotal: 5.57s\tremaining: 3m 28s\n",
      "13:\tlearn: 2.3564781\ttotal: 5.99s\tremaining: 3m 27s\n",
      "14:\tlearn: 2.3556510\ttotal: 6.37s\tremaining: 3m 25s\n",
      "15:\tlearn: 2.3548520\ttotal: 6.81s\tremaining: 3m 26s\n",
      "16:\tlearn: 2.3542215\ttotal: 7.23s\tremaining: 3m 25s\n",
      "17:\tlearn: 2.3535290\ttotal: 7.63s\tremaining: 3m 24s\n",
      "18:\tlearn: 2.3530095\ttotal: 8.09s\tremaining: 3m 24s\n",
      "19:\tlearn: 2.3520227\ttotal: 8.5s\tremaining: 3m 24s\n",
      "20:\tlearn: 2.3514627\ttotal: 8.88s\tremaining: 3m 22s\n",
      "21:\tlearn: 2.3509665\ttotal: 9.31s\tremaining: 3m 22s\n",
      "22:\tlearn: 2.3502115\ttotal: 9.72s\tremaining: 3m 21s\n",
      "23:\tlearn: 2.3497983\ttotal: 10.2s\tremaining: 3m 21s\n",
      "24:\tlearn: 2.3493633\ttotal: 10.5s\tremaining: 3m 19s\n",
      "25:\tlearn: 2.3487852\ttotal: 10.9s\tremaining: 3m 18s\n",
      "26:\tlearn: 2.3468703\ttotal: 11.4s\tremaining: 3m 19s\n",
      "27:\tlearn: 2.3462309\ttotal: 11.9s\tremaining: 3m 20s\n",
      "28:\tlearn: 2.3458539\ttotal: 12.3s\tremaining: 3m 19s\n",
      "29:\tlearn: 2.3453551\ttotal: 12.6s\tremaining: 3m 18s\n",
      "30:\tlearn: 2.3449775\ttotal: 13s\tremaining: 3m 17s\n",
      "31:\tlearn: 2.3444367\ttotal: 13.5s\tremaining: 3m 17s\n",
      "32:\tlearn: 2.3441284\ttotal: 13.9s\tremaining: 3m 16s\n",
      "33:\tlearn: 2.3429294\ttotal: 14.3s\tremaining: 3m 15s\n",
      "34:\tlearn: 2.3426701\ttotal: 14.7s\tremaining: 3m 14s\n",
      "35:\tlearn: 2.3422159\ttotal: 15.1s\tremaining: 3m 14s\n",
      "36:\tlearn: 2.3417827\ttotal: 15.4s\tremaining: 3m 13s\n",
      "37:\tlearn: 2.3413753\ttotal: 15.8s\tremaining: 3m 12s\n",
      "38:\tlearn: 2.3408833\ttotal: 16.3s\tremaining: 3m 12s\n",
      "39:\tlearn: 2.3406772\ttotal: 16.6s\tremaining: 3m 11s\n",
      "40:\tlearn: 2.3397710\ttotal: 17s\tremaining: 3m 10s\n",
      "41:\tlearn: 2.3392215\ttotal: 17.5s\tremaining: 3m 10s\n",
      "42:\tlearn: 2.3388626\ttotal: 17.9s\tremaining: 3m 10s\n",
      "43:\tlearn: 2.3385038\ttotal: 18.3s\tremaining: 3m 9s\n",
      "44:\tlearn: 2.3383347\ttotal: 18.6s\tremaining: 3m 8s\n",
      "45:\tlearn: 2.3380129\ttotal: 19s\tremaining: 3m 7s\n",
      "46:\tlearn: 2.3372149\ttotal: 19.5s\tremaining: 3m 7s\n",
      "47:\tlearn: 2.3369622\ttotal: 19.8s\tremaining: 3m 6s\n",
      "48:\tlearn: 2.3365120\ttotal: 20.2s\tremaining: 3m 6s\n",
      "49:\tlearn: 2.3359294\ttotal: 20.6s\tremaining: 3m 5s\n",
      "50:\tlearn: 2.3357121\ttotal: 21s\tremaining: 3m 4s\n",
      "51:\tlearn: 2.3355443\ttotal: 21.4s\tremaining: 3m 4s\n",
      "52:\tlearn: 2.3353339\ttotal: 21.8s\tremaining: 3m 3s\n",
      "53:\tlearn: 2.3350736\ttotal: 22.2s\tremaining: 3m 3s\n",
      "54:\tlearn: 2.3346294\ttotal: 22.6s\tremaining: 3m 2s\n",
      "55:\tlearn: 2.3342408\ttotal: 23s\tremaining: 3m 2s\n",
      "56:\tlearn: 2.3340989\ttotal: 23.3s\tremaining: 3m 1s\n",
      "57:\tlearn: 2.3326689\ttotal: 23.7s\tremaining: 3m\n",
      "58:\tlearn: 2.3324645\ttotal: 24.1s\tremaining: 3m\n",
      "59:\tlearn: 2.3318466\ttotal: 24.5s\tremaining: 2m 59s\n",
      "60:\tlearn: 2.3314157\ttotal: 24.9s\tremaining: 2m 59s\n",
      "61:\tlearn: 2.3311554\ttotal: 25.3s\tremaining: 2m 58s\n",
      "62:\tlearn: 2.3308748\ttotal: 25.7s\tremaining: 2m 58s\n",
      "63:\tlearn: 2.3304759\ttotal: 26.1s\tremaining: 2m 57s\n",
      "64:\tlearn: 2.3302512\ttotal: 26.5s\tremaining: 2m 57s\n",
      "65:\tlearn: 2.3299411\ttotal: 26.9s\tremaining: 2m 56s\n",
      "66:\tlearn: 2.3297340\ttotal: 27.3s\tremaining: 2m 56s\n",
      "67:\tlearn: 2.3295721\ttotal: 27.7s\tremaining: 2m 55s\n",
      "68:\tlearn: 2.3290884\ttotal: 28.1s\tremaining: 2m 55s\n",
      "69:\tlearn: 2.3288695\ttotal: 28.4s\tremaining: 2m 54s\n",
      "70:\tlearn: 2.3287709\ttotal: 28.8s\tremaining: 2m 54s\n",
      "71:\tlearn: 2.3274278\ttotal: 29.2s\tremaining: 2m 53s\n",
      "72:\tlearn: 2.3270336\ttotal: 29.6s\tremaining: 2m 53s\n",
      "73:\tlearn: 2.3259429\ttotal: 30.1s\tremaining: 2m 53s\n",
      "74:\tlearn: 2.3254784\ttotal: 30.6s\tremaining: 2m 53s\n",
      "75:\tlearn: 2.3252519\ttotal: 30.9s\tremaining: 2m 52s\n",
      "76:\tlearn: 2.3249996\ttotal: 31.3s\tremaining: 2m 51s\n",
      "77:\tlearn: 2.3247243\ttotal: 31.7s\tremaining: 2m 51s\n",
      "78:\tlearn: 2.3245731\ttotal: 32.1s\tremaining: 2m 50s\n",
      "79:\tlearn: 2.3242580\ttotal: 32.5s\tremaining: 2m 50s\n",
      "80:\tlearn: 2.3239522\ttotal: 32.9s\tremaining: 2m 49s\n",
      "81:\tlearn: 2.3237923\ttotal: 33.2s\tremaining: 2m 49s\n",
      "82:\tlearn: 2.3233328\ttotal: 33.7s\tremaining: 2m 49s\n",
      "83:\tlearn: 2.3228974\ttotal: 34.2s\tremaining: 2m 49s\n",
      "84:\tlearn: 2.3227683\ttotal: 34.7s\tremaining: 2m 49s\n",
      "85:\tlearn: 2.3225358\ttotal: 35.1s\tremaining: 2m 48s\n",
      "86:\tlearn: 2.3222736\ttotal: 35.5s\tremaining: 2m 48s\n",
      "87:\tlearn: 2.3221111\ttotal: 35.8s\tremaining: 2m 47s\n",
      "88:\tlearn: 2.3217885\ttotal: 36.2s\tremaining: 2m 47s\n",
      "89:\tlearn: 2.3215588\ttotal: 36.6s\tremaining: 2m 46s\n",
      "90:\tlearn: 2.3212080\ttotal: 37s\tremaining: 2m 46s\n",
      "91:\tlearn: 2.3211306\ttotal: 37.3s\tremaining: 2m 45s\n",
      "92:\tlearn: 2.3208219\ttotal: 37.8s\tremaining: 2m 45s\n",
      "93:\tlearn: 2.3207130\ttotal: 38.2s\tremaining: 2m 44s\n",
      "94:\tlearn: 2.3205192\ttotal: 38.6s\tremaining: 2m 44s\n",
      "95:\tlearn: 2.3202562\ttotal: 39s\tremaining: 2m 44s\n",
      "96:\tlearn: 2.3201607\ttotal: 39.4s\tremaining: 2m 43s\n",
      "97:\tlearn: 2.3200035\ttotal: 39.7s\tremaining: 2m 42s\n",
      "98:\tlearn: 2.3195049\ttotal: 40.1s\tremaining: 2m 42s\n",
      "99:\tlearn: 2.3191236\ttotal: 40.6s\tremaining: 2m 42s\n",
      "100:\tlearn: 2.3189221\ttotal: 40.9s\tremaining: 2m 41s\n",
      "101:\tlearn: 2.3186592\ttotal: 41.3s\tremaining: 2m 41s\n",
      "102:\tlearn: 2.3185201\ttotal: 41.7s\tremaining: 2m 40s\n",
      "103:\tlearn: 2.3183175\ttotal: 42.1s\tremaining: 2m 40s\n",
      "104:\tlearn: 2.3182097\ttotal: 42.5s\tremaining: 2m 39s\n",
      "105:\tlearn: 2.3181174\ttotal: 42.9s\tremaining: 2m 39s\n",
      "106:\tlearn: 2.3180705\ttotal: 43.3s\tremaining: 2m 39s\n",
      "107:\tlearn: 2.3178047\ttotal: 43.8s\tremaining: 2m 38s\n",
      "108:\tlearn: 2.3176457\ttotal: 44.3s\tremaining: 2m 38s\n",
      "109:\tlearn: 2.3174557\ttotal: 44.7s\tremaining: 2m 38s\n",
      "110:\tlearn: 2.3173384\ttotal: 45.2s\tremaining: 2m 38s\n",
      "111:\tlearn: 2.3170053\ttotal: 45.6s\tremaining: 2m 37s\n",
      "112:\tlearn: 2.3166948\ttotal: 45.9s\tremaining: 2m 37s\n",
      "113:\tlearn: 2.3163070\ttotal: 46.4s\tremaining: 2m 36s\n",
      "114:\tlearn: 2.3161152\ttotal: 46.7s\tremaining: 2m 36s\n",
      "115:\tlearn: 2.3159808\ttotal: 47.2s\tremaining: 2m 36s\n",
      "116:\tlearn: 2.3156518\ttotal: 47.6s\tremaining: 2m 35s\n",
      "117:\tlearn: 2.3152247\ttotal: 48s\tremaining: 2m 35s\n",
      "118:\tlearn: 2.3148903\ttotal: 48.5s\tremaining: 2m 35s\n",
      "119:\tlearn: 2.3146912\ttotal: 49s\tremaining: 2m 35s\n",
      "120:\tlearn: 2.3138284\ttotal: 49.5s\tremaining: 2m 34s\n",
      "121:\tlearn: 2.3136368\ttotal: 49.9s\tremaining: 2m 34s\n",
      "122:\tlearn: 2.3135357\ttotal: 50.3s\tremaining: 2m 34s\n",
      "123:\tlearn: 2.3134591\ttotal: 50.6s\tremaining: 2m 33s\n",
      "124:\tlearn: 2.3131756\ttotal: 51.1s\tremaining: 2m 33s\n",
      "125:\tlearn: 2.3129048\ttotal: 51.5s\tremaining: 2m 32s\n",
      "126:\tlearn: 2.3125580\ttotal: 51.9s\tremaining: 2m 32s\n",
      "127:\tlearn: 2.3124480\ttotal: 52.2s\tremaining: 2m 31s\n",
      "128:\tlearn: 2.3124117\ttotal: 52.6s\tremaining: 2m 31s\n",
      "129:\tlearn: 2.3121856\ttotal: 52.9s\tremaining: 2m 30s\n",
      "130:\tlearn: 2.3119591\ttotal: 53.3s\tremaining: 2m 30s\n",
      "131:\tlearn: 2.3118977\ttotal: 53.7s\tremaining: 2m 29s\n",
      "132:\tlearn: 2.3118245\ttotal: 54.1s\tremaining: 2m 29s\n",
      "133:\tlearn: 2.3117632\ttotal: 54.5s\tremaining: 2m 28s\n",
      "134:\tlearn: 2.3115529\ttotal: 54.9s\tremaining: 2m 28s\n",
      "135:\tlearn: 2.3113879\ttotal: 55.3s\tremaining: 2m 28s\n",
      "136:\tlearn: 2.3112429\ttotal: 55.7s\tremaining: 2m 27s\n",
      "137:\tlearn: 2.3109699\ttotal: 56.2s\tremaining: 2m 27s\n",
      "138:\tlearn: 2.3108568\ttotal: 56.6s\tremaining: 2m 26s\n",
      "139:\tlearn: 2.3105470\ttotal: 57.1s\tremaining: 2m 26s\n",
      "140:\tlearn: 2.3103269\ttotal: 57.5s\tremaining: 2m 26s\n",
      "141:\tlearn: 2.3101135\ttotal: 57.9s\tremaining: 2m 25s\n",
      "142:\tlearn: 2.3099525\ttotal: 58.3s\tremaining: 2m 25s\n",
      "143:\tlearn: 2.3097074\ttotal: 58.7s\tremaining: 2m 25s\n",
      "144:\tlearn: 2.3096460\ttotal: 59.1s\tremaining: 2m 24s\n",
      "145:\tlearn: 2.3093067\ttotal: 59.6s\tremaining: 2m 24s\n",
      "146:\tlearn: 2.3091266\ttotal: 60s\tremaining: 2m 23s\n",
      "147:\tlearn: 2.3090265\ttotal: 1m\tremaining: 2m 23s\n",
      "148:\tlearn: 2.3083168\ttotal: 1m\tremaining: 2m 23s\n",
      "149:\tlearn: 2.3081806\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "150:\tlearn: 2.3075439\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "151:\tlearn: 2.3072595\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "152:\tlearn: 2.3070493\ttotal: 1m 2s\tremaining: 2m 22s\n",
      "153:\tlearn: 2.3068977\ttotal: 1m 3s\tremaining: 2m 22s\n",
      "154:\tlearn: 2.3067671\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "155:\tlearn: 2.3064841\ttotal: 1m 4s\tremaining: 2m 21s\n",
      "156:\tlearn: 2.3063371\ttotal: 1m 4s\tremaining: 2m 21s\n",
      "157:\tlearn: 2.3061037\ttotal: 1m 5s\tremaining: 2m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 2.3059939\ttotal: 1m 5s\tremaining: 2m 20s\n",
      "159:\tlearn: 2.3057357\ttotal: 1m 6s\tremaining: 2m 20s\n",
      "160:\tlearn: 2.3056228\ttotal: 1m 6s\tremaining: 2m 19s\n",
      "161:\tlearn: 2.3055297\ttotal: 1m 6s\tremaining: 2m 19s\n",
      "162:\tlearn: 2.3053082\ttotal: 1m 7s\tremaining: 2m 19s\n",
      "163:\tlearn: 2.3051876\ttotal: 1m 7s\tremaining: 2m 18s\n",
      "164:\tlearn: 2.3051175\ttotal: 1m 8s\tremaining: 2m 18s\n",
      "165:\tlearn: 2.3048207\ttotal: 1m 8s\tremaining: 2m 18s\n",
      "166:\tlearn: 2.3047608\ttotal: 1m 8s\tremaining: 2m 17s\n",
      "167:\tlearn: 2.3047234\ttotal: 1m 9s\tremaining: 2m 17s\n",
      "168:\tlearn: 2.3045461\ttotal: 1m 9s\tremaining: 2m 16s\n",
      "169:\tlearn: 2.3044090\ttotal: 1m 10s\tremaining: 2m 16s\n",
      "170:\tlearn: 2.3042246\ttotal: 1m 10s\tremaining: 2m 15s\n",
      "171:\tlearn: 2.3036682\ttotal: 1m 11s\tremaining: 2m 15s\n",
      "172:\tlearn: 2.3035211\ttotal: 1m 11s\tremaining: 2m 15s\n",
      "173:\tlearn: 2.3032767\ttotal: 1m 11s\tremaining: 2m 14s\n",
      "174:\tlearn: 2.3030885\ttotal: 1m 12s\tremaining: 2m 14s\n",
      "175:\tlearn: 2.3026336\ttotal: 1m 12s\tremaining: 2m 14s\n",
      "176:\tlearn: 2.3024977\ttotal: 1m 13s\tremaining: 2m 13s\n",
      "177:\tlearn: 2.3023709\ttotal: 1m 13s\tremaining: 2m 13s\n",
      "178:\tlearn: 2.3023179\ttotal: 1m 14s\tremaining: 2m 12s\n",
      "179:\tlearn: 2.3021840\ttotal: 1m 14s\tremaining: 2m 12s\n",
      "180:\tlearn: 2.3021323\ttotal: 1m 14s\tremaining: 2m 11s\n",
      "181:\tlearn: 2.3020547\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "182:\tlearn: 2.3019014\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "183:\tlearn: 2.3017580\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "184:\tlearn: 2.3017217\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "185:\tlearn: 2.3015363\ttotal: 1m 16s\tremaining: 2m 9s\n",
      "186:\tlearn: 2.3014469\ttotal: 1m 17s\tremaining: 2m 9s\n",
      "187:\tlearn: 2.3012578\ttotal: 1m 17s\tremaining: 2m 8s\n",
      "188:\tlearn: 2.3010308\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "189:\tlearn: 2.3008664\ttotal: 1m 18s\tremaining: 2m 8s\n",
      "190:\tlearn: 2.3007526\ttotal: 1m 18s\tremaining: 2m 7s\n",
      "191:\tlearn: 2.3006037\ttotal: 1m 19s\tremaining: 2m 7s\n",
      "192:\tlearn: 2.3002011\ttotal: 1m 19s\tremaining: 2m 6s\n",
      "193:\tlearn: 2.2999889\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "194:\tlearn: 2.2998470\ttotal: 1m 20s\tremaining: 2m 6s\n",
      "195:\tlearn: 2.2996995\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "196:\tlearn: 2.2993702\ttotal: 1m 21s\tremaining: 2m 5s\n",
      "197:\tlearn: 2.2991679\ttotal: 1m 22s\tremaining: 2m 5s\n",
      "198:\tlearn: 2.2990427\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "199:\tlearn: 2.2989907\ttotal: 1m 22s\tremaining: 2m 4s\n",
      "200:\tlearn: 2.2988811\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "201:\tlearn: 2.2988184\ttotal: 1m 23s\tremaining: 2m 3s\n",
      "202:\tlearn: 2.2986974\ttotal: 1m 23s\tremaining: 2m 2s\n",
      "203:\tlearn: 2.2985737\ttotal: 1m 24s\tremaining: 2m 2s\n",
      "204:\tlearn: 2.2984252\ttotal: 1m 24s\tremaining: 2m 1s\n",
      "205:\tlearn: 2.2983817\ttotal: 1m 25s\tremaining: 2m 1s\n",
      "206:\tlearn: 2.2982739\ttotal: 1m 25s\tremaining: 2m 1s\n",
      "207:\tlearn: 2.2980601\ttotal: 1m 25s\tremaining: 2m\n",
      "208:\tlearn: 2.2979051\ttotal: 1m 26s\tremaining: 2m\n",
      "209:\tlearn: 2.2978156\ttotal: 1m 26s\tremaining: 1m 59s\n",
      "210:\tlearn: 2.2977699\ttotal: 1m 27s\tremaining: 1m 59s\n",
      "211:\tlearn: 2.2977263\ttotal: 1m 27s\tremaining: 1m 58s\n",
      "212:\tlearn: 2.2976188\ttotal: 1m 27s\tremaining: 1m 58s\n",
      "213:\tlearn: 2.2974778\ttotal: 1m 28s\tremaining: 1m 57s\n",
      "214:\tlearn: 2.2973026\ttotal: 1m 28s\tremaining: 1m 57s\n",
      "215:\tlearn: 2.2971712\ttotal: 1m 29s\tremaining: 1m 57s\n",
      "216:\tlearn: 2.2970767\ttotal: 1m 29s\tremaining: 1m 56s\n",
      "217:\tlearn: 2.2969696\ttotal: 1m 29s\tremaining: 1m 56s\n",
      "218:\tlearn: 2.2969240\ttotal: 1m 30s\tremaining: 1m 55s\n",
      "219:\tlearn: 2.2968101\ttotal: 1m 30s\tremaining: 1m 55s\n",
      "220:\tlearn: 2.2966908\ttotal: 1m 31s\tremaining: 1m 55s\n",
      "221:\tlearn: 2.2965454\ttotal: 1m 31s\tremaining: 1m 54s\n",
      "222:\tlearn: 2.2963475\ttotal: 1m 31s\tremaining: 1m 54s\n",
      "223:\tlearn: 2.2962440\ttotal: 1m 32s\tremaining: 1m 53s\n",
      "224:\tlearn: 2.2959470\ttotal: 1m 32s\tremaining: 1m 53s\n",
      "225:\tlearn: 2.2958378\ttotal: 1m 33s\tremaining: 1m 53s\n",
      "226:\tlearn: 2.2957544\ttotal: 1m 33s\tremaining: 1m 52s\n",
      "227:\tlearn: 2.2955620\ttotal: 1m 34s\tremaining: 1m 52s\n",
      "228:\tlearn: 2.2953780\ttotal: 1m 34s\tremaining: 1m 51s\n",
      "229:\tlearn: 2.2952504\ttotal: 1m 34s\tremaining: 1m 51s\n",
      "230:\tlearn: 2.2950865\ttotal: 1m 35s\tremaining: 1m 51s\n",
      "231:\tlearn: 2.2949230\ttotal: 1m 35s\tremaining: 1m 50s\n",
      "232:\tlearn: 2.2946786\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "233:\tlearn: 2.2945950\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "234:\tlearn: 2.2944905\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "235:\tlearn: 2.2944088\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "236:\tlearn: 2.2943777\ttotal: 1m 37s\tremaining: 1m 48s\n",
      "237:\tlearn: 2.2942889\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "238:\tlearn: 2.2942543\ttotal: 1m 38s\tremaining: 1m 47s\n",
      "239:\tlearn: 2.2941656\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "240:\tlearn: 2.2941372\ttotal: 1m 39s\tremaining: 1m 46s\n",
      "241:\tlearn: 2.2940184\ttotal: 1m 39s\tremaining: 1m 46s\n",
      "242:\tlearn: 2.2938693\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "243:\tlearn: 2.2937820\ttotal: 1m 40s\tremaining: 1m 45s\n",
      "244:\tlearn: 2.2935441\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "245:\tlearn: 2.2933703\ttotal: 1m 41s\tremaining: 1m 44s\n",
      "246:\tlearn: 2.2931926\ttotal: 1m 41s\tremaining: 1m 44s\n",
      "247:\tlearn: 2.2931049\ttotal: 1m 42s\tremaining: 1m 44s\n",
      "248:\tlearn: 2.2929976\ttotal: 1m 42s\tremaining: 1m 43s\n",
      "249:\tlearn: 2.2929003\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "250:\tlearn: 2.2928123\ttotal: 1m 43s\tremaining: 1m 42s\n",
      "251:\tlearn: 2.2927171\ttotal: 1m 44s\tremaining: 1m 42s\n",
      "252:\tlearn: 2.2925844\ttotal: 1m 44s\tremaining: 1m 41s\n",
      "253:\tlearn: 2.2924544\ttotal: 1m 44s\tremaining: 1m 41s\n",
      "254:\tlearn: 2.2922068\ttotal: 1m 45s\tremaining: 1m 41s\n",
      "255:\tlearn: 2.2921708\ttotal: 1m 45s\tremaining: 1m 40s\n",
      "256:\tlearn: 2.2920588\ttotal: 1m 46s\tremaining: 1m 40s\n",
      "257:\tlearn: 2.2919242\ttotal: 1m 46s\tremaining: 1m 39s\n",
      "258:\tlearn: 2.2917939\ttotal: 1m 47s\tremaining: 1m 39s\n",
      "259:\tlearn: 2.2916320\ttotal: 1m 47s\tremaining: 1m 39s\n",
      "260:\tlearn: 2.2915875\ttotal: 1m 47s\tremaining: 1m 38s\n",
      "261:\tlearn: 2.2914891\ttotal: 1m 48s\tremaining: 1m 38s\n",
      "262:\tlearn: 2.2914147\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "263:\tlearn: 2.2912558\ttotal: 1m 48s\tremaining: 1m 37s\n",
      "264:\tlearn: 2.2910520\ttotal: 1m 49s\tremaining: 1m 37s\n",
      "265:\tlearn: 2.2910233\ttotal: 1m 49s\tremaining: 1m 36s\n",
      "266:\tlearn: 2.2908919\ttotal: 1m 50s\tremaining: 1m 36s\n",
      "267:\tlearn: 2.2907756\ttotal: 1m 50s\tremaining: 1m 35s\n",
      "268:\tlearn: 2.2906748\ttotal: 1m 50s\tremaining: 1m 35s\n",
      "269:\tlearn: 2.2906024\ttotal: 1m 51s\tremaining: 1m 34s\n",
      "270:\tlearn: 2.2904466\ttotal: 1m 51s\tremaining: 1m 34s\n",
      "271:\tlearn: 2.2903604\ttotal: 1m 52s\tremaining: 1m 34s\n",
      "272:\tlearn: 2.2901624\ttotal: 1m 52s\tremaining: 1m 33s\n",
      "273:\tlearn: 2.2901040\ttotal: 1m 53s\tremaining: 1m 33s\n",
      "274:\tlearn: 2.2899694\ttotal: 1m 53s\tremaining: 1m 32s\n",
      "275:\tlearn: 2.2898892\ttotal: 1m 53s\tremaining: 1m 32s\n",
      "276:\tlearn: 2.2897202\ttotal: 1m 54s\tremaining: 1m 32s\n",
      "277:\tlearn: 2.2895955\ttotal: 1m 54s\tremaining: 1m 31s\n",
      "278:\tlearn: 2.2894902\ttotal: 1m 55s\tremaining: 1m 31s\n",
      "279:\tlearn: 2.2894167\ttotal: 1m 55s\tremaining: 1m 30s\n",
      "280:\tlearn: 2.2892755\ttotal: 1m 56s\tremaining: 1m 30s\n",
      "281:\tlearn: 2.2891873\ttotal: 1m 56s\tremaining: 1m 30s\n",
      "282:\tlearn: 2.2891504\ttotal: 1m 56s\tremaining: 1m 29s\n",
      "283:\tlearn: 2.2891030\ttotal: 1m 57s\tremaining: 1m 29s\n",
      "284:\tlearn: 2.2889622\ttotal: 1m 57s\tremaining: 1m 28s\n",
      "285:\tlearn: 2.2888703\ttotal: 1m 58s\tremaining: 1m 28s\n",
      "286:\tlearn: 2.2887999\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "287:\tlearn: 2.2887349\ttotal: 1m 58s\tremaining: 1m 27s\n",
      "288:\tlearn: 2.2886308\ttotal: 1m 59s\tremaining: 1m 27s\n",
      "289:\tlearn: 2.2885104\ttotal: 1m 59s\tremaining: 1m 26s\n",
      "290:\tlearn: 2.2884711\ttotal: 2m\tremaining: 1m 26s\n",
      "291:\tlearn: 2.2883018\ttotal: 2m\tremaining: 1m 25s\n",
      "292:\tlearn: 2.2882374\ttotal: 2m\tremaining: 1m 25s\n",
      "293:\tlearn: 2.2881584\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "294:\tlearn: 2.2880122\ttotal: 2m 1s\tremaining: 1m 24s\n",
      "295:\tlearn: 2.2878950\ttotal: 2m 2s\tremaining: 1m 24s\n",
      "296:\tlearn: 2.2878289\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "297:\tlearn: 2.2877517\ttotal: 2m 2s\tremaining: 1m 23s\n",
      "298:\tlearn: 2.2877159\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "299:\tlearn: 2.2876533\ttotal: 2m 3s\tremaining: 1m 22s\n",
      "300:\tlearn: 2.2876336\ttotal: 2m 4s\tremaining: 1m 22s\n",
      "301:\tlearn: 2.2876073\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "302:\tlearn: 2.2875331\ttotal: 2m 4s\tremaining: 1m 21s\n",
      "303:\tlearn: 2.2874357\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "304:\tlearn: 2.2873593\ttotal: 2m 5s\tremaining: 1m 20s\n",
      "305:\tlearn: 2.2872776\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "306:\tlearn: 2.2871706\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "307:\tlearn: 2.2870938\ttotal: 2m 6s\tremaining: 1m 19s\n",
      "308:\tlearn: 2.2870793\ttotal: 2m 7s\tremaining: 1m 18s\n",
      "309:\tlearn: 2.2869949\ttotal: 2m 7s\tremaining: 1m 18s\n",
      "310:\tlearn: 2.2869466\ttotal: 2m 8s\tremaining: 1m 17s\n",
      "311:\tlearn: 2.2868272\ttotal: 2m 8s\tremaining: 1m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312:\tlearn: 2.2867977\ttotal: 2m 8s\tremaining: 1m 17s\n",
      "313:\tlearn: 2.2867012\ttotal: 2m 9s\tremaining: 1m 16s\n",
      "314:\tlearn: 2.2865355\ttotal: 2m 9s\tremaining: 1m 16s\n",
      "315:\tlearn: 2.2864817\ttotal: 2m 10s\tremaining: 1m 15s\n",
      "316:\tlearn: 2.2864216\ttotal: 2m 10s\tremaining: 1m 15s\n",
      "317:\tlearn: 2.2863563\ttotal: 2m 11s\tremaining: 1m 15s\n",
      "318:\tlearn: 2.2862637\ttotal: 2m 11s\tremaining: 1m 14s\n",
      "319:\tlearn: 2.2861483\ttotal: 2m 11s\tremaining: 1m 14s\n",
      "320:\tlearn: 2.2861109\ttotal: 2m 12s\tremaining: 1m 13s\n",
      "321:\tlearn: 2.2860578\ttotal: 2m 12s\tremaining: 1m 13s\n",
      "322:\tlearn: 2.2859944\ttotal: 2m 13s\tremaining: 1m 12s\n",
      "323:\tlearn: 2.2858751\ttotal: 2m 13s\tremaining: 1m 12s\n",
      "324:\tlearn: 2.2858567\ttotal: 2m 13s\tremaining: 1m 12s\n",
      "325:\tlearn: 2.2857701\ttotal: 2m 14s\tremaining: 1m 11s\n",
      "326:\tlearn: 2.2857257\ttotal: 2m 14s\tremaining: 1m 11s\n",
      "327:\tlearn: 2.2856806\ttotal: 2m 15s\tremaining: 1m 10s\n",
      "328:\tlearn: 2.2856067\ttotal: 2m 15s\tremaining: 1m 10s\n",
      "329:\tlearn: 2.2855384\ttotal: 2m 15s\tremaining: 1m 10s\n",
      "330:\tlearn: 2.2854429\ttotal: 2m 16s\tremaining: 1m 9s\n",
      "331:\tlearn: 2.2853890\ttotal: 2m 16s\tremaining: 1m 9s\n",
      "332:\tlearn: 2.2852789\ttotal: 2m 17s\tremaining: 1m 8s\n",
      "333:\tlearn: 2.2851795\ttotal: 2m 17s\tremaining: 1m 8s\n",
      "334:\tlearn: 2.2850987\ttotal: 2m 18s\tremaining: 1m 8s\n",
      "335:\tlearn: 2.2850499\ttotal: 2m 18s\tremaining: 1m 7s\n",
      "336:\tlearn: 2.2849605\ttotal: 2m 18s\tremaining: 1m 7s\n",
      "337:\tlearn: 2.2848893\ttotal: 2m 19s\tremaining: 1m 6s\n",
      "338:\tlearn: 2.2848507\ttotal: 2m 19s\tremaining: 1m 6s\n",
      "339:\tlearn: 2.2847743\ttotal: 2m 20s\tremaining: 1m 5s\n",
      "340:\tlearn: 2.2846902\ttotal: 2m 20s\tremaining: 1m 5s\n",
      "341:\tlearn: 2.2846110\ttotal: 2m 21s\tremaining: 1m 5s\n",
      "342:\tlearn: 2.2845847\ttotal: 2m 21s\tremaining: 1m 4s\n",
      "343:\tlearn: 2.2845198\ttotal: 2m 21s\tremaining: 1m 4s\n",
      "344:\tlearn: 2.2844486\ttotal: 2m 22s\tremaining: 1m 3s\n",
      "345:\tlearn: 2.2843644\ttotal: 2m 22s\tremaining: 1m 3s\n",
      "346:\tlearn: 2.2843074\ttotal: 2m 23s\tremaining: 1m 3s\n",
      "347:\tlearn: 2.2842505\ttotal: 2m 23s\tremaining: 1m 2s\n",
      "348:\tlearn: 2.2841198\ttotal: 2m 23s\tremaining: 1m 2s\n",
      "349:\tlearn: 2.2840574\ttotal: 2m 24s\tremaining: 1m 1s\n",
      "350:\tlearn: 2.2839904\ttotal: 2m 24s\tremaining: 1m 1s\n",
      "351:\tlearn: 2.2839584\ttotal: 2m 24s\tremaining: 1m\n",
      "352:\tlearn: 2.2839437\ttotal: 2m 25s\tremaining: 1m\n",
      "353:\tlearn: 2.2838080\ttotal: 2m 25s\tremaining: 1m\n",
      "354:\tlearn: 2.2837383\ttotal: 2m 26s\tremaining: 59.7s\n",
      "355:\tlearn: 2.2836876\ttotal: 2m 26s\tremaining: 59.2s\n",
      "356:\tlearn: 2.2836059\ttotal: 2m 26s\tremaining: 58.8s\n",
      "357:\tlearn: 2.2835429\ttotal: 2m 27s\tremaining: 58.4s\n",
      "358:\tlearn: 2.2834702\ttotal: 2m 27s\tremaining: 58s\n",
      "359:\tlearn: 2.2833926\ttotal: 2m 28s\tremaining: 57.6s\n",
      "360:\tlearn: 2.2833384\ttotal: 2m 28s\tremaining: 57.2s\n",
      "361:\tlearn: 2.2832627\ttotal: 2m 28s\tremaining: 56.8s\n",
      "362:\tlearn: 2.2832221\ttotal: 2m 29s\tremaining: 56.4s\n",
      "363:\tlearn: 2.2831587\ttotal: 2m 29s\tremaining: 55.9s\n",
      "364:\tlearn: 2.2831001\ttotal: 2m 30s\tremaining: 55.5s\n",
      "365:\tlearn: 2.2830463\ttotal: 2m 30s\tremaining: 55.1s\n",
      "366:\tlearn: 2.2828692\ttotal: 2m 30s\tremaining: 54.7s\n",
      "367:\tlearn: 2.2827952\ttotal: 2m 31s\tremaining: 54.3s\n",
      "368:\tlearn: 2.2827292\ttotal: 2m 31s\tremaining: 53.9s\n",
      "369:\tlearn: 2.2826625\ttotal: 2m 32s\tremaining: 53.5s\n",
      "370:\tlearn: 2.2825936\ttotal: 2m 32s\tremaining: 53s\n",
      "371:\tlearn: 2.2825511\ttotal: 2m 32s\tremaining: 52.6s\n",
      "372:\tlearn: 2.2824986\ttotal: 2m 33s\tremaining: 52.2s\n",
      "373:\tlearn: 2.2824338\ttotal: 2m 33s\tremaining: 51.8s\n",
      "374:\tlearn: 2.2823827\ttotal: 2m 34s\tremaining: 51.4s\n",
      "375:\tlearn: 2.2822990\ttotal: 2m 34s\tremaining: 51s\n",
      "376:\tlearn: 2.2822443\ttotal: 2m 35s\tremaining: 50.6s\n",
      "377:\tlearn: 2.2821861\ttotal: 2m 35s\tremaining: 50.2s\n",
      "378:\tlearn: 2.2821333\ttotal: 2m 35s\tremaining: 49.7s\n",
      "379:\tlearn: 2.2820775\ttotal: 2m 36s\tremaining: 49.3s\n",
      "380:\tlearn: 2.2820265\ttotal: 2m 36s\tremaining: 48.9s\n",
      "381:\tlearn: 2.2819176\ttotal: 2m 37s\tremaining: 48.5s\n",
      "382:\tlearn: 2.2818745\ttotal: 2m 37s\tremaining: 48.1s\n",
      "383:\tlearn: 2.2817310\ttotal: 2m 37s\tremaining: 47.7s\n",
      "384:\tlearn: 2.2816861\ttotal: 2m 38s\tremaining: 47.3s\n",
      "385:\tlearn: 2.2816173\ttotal: 2m 38s\tremaining: 46.9s\n",
      "386:\tlearn: 2.2815343\ttotal: 2m 39s\tremaining: 46.5s\n",
      "387:\tlearn: 2.2814436\ttotal: 2m 39s\tremaining: 46.1s\n",
      "388:\tlearn: 2.2814108\ttotal: 2m 39s\tremaining: 45.6s\n",
      "389:\tlearn: 2.2813832\ttotal: 2m 40s\tremaining: 45.2s\n",
      "390:\tlearn: 2.2813251\ttotal: 2m 40s\tremaining: 44.8s\n",
      "391:\tlearn: 2.2812518\ttotal: 2m 41s\tremaining: 44.4s\n",
      "392:\tlearn: 2.2812406\ttotal: 2m 41s\tremaining: 44s\n",
      "393:\tlearn: 2.2811926\ttotal: 2m 41s\tremaining: 43.5s\n",
      "394:\tlearn: 2.2811490\ttotal: 2m 42s\tremaining: 43.1s\n",
      "395:\tlearn: 2.2810388\ttotal: 2m 42s\tremaining: 42.7s\n",
      "396:\tlearn: 2.2809686\ttotal: 2m 43s\tremaining: 42.3s\n",
      "397:\tlearn: 2.2808053\ttotal: 2m 43s\tremaining: 41.9s\n",
      "398:\tlearn: 2.2807670\ttotal: 2m 43s\tremaining: 41.5s\n",
      "399:\tlearn: 2.2807127\ttotal: 2m 44s\tremaining: 41.1s\n",
      "400:\tlearn: 2.2806546\ttotal: 2m 44s\tremaining: 40.7s\n",
      "401:\tlearn: 2.2805747\ttotal: 2m 45s\tremaining: 40.3s\n",
      "402:\tlearn: 2.2805365\ttotal: 2m 45s\tremaining: 39.8s\n",
      "403:\tlearn: 2.2805047\ttotal: 2m 45s\tremaining: 39.4s\n",
      "404:\tlearn: 2.2804499\ttotal: 2m 46s\tremaining: 39s\n",
      "405:\tlearn: 2.2804156\ttotal: 2m 46s\tremaining: 38.6s\n",
      "406:\tlearn: 2.2803780\ttotal: 2m 47s\tremaining: 38.2s\n",
      "407:\tlearn: 2.2803280\ttotal: 2m 47s\tremaining: 37.8s\n",
      "408:\tlearn: 2.2802877\ttotal: 2m 47s\tremaining: 37.4s\n",
      "409:\tlearn: 2.2802757\ttotal: 2m 48s\tremaining: 36.9s\n",
      "410:\tlearn: 2.2802438\ttotal: 2m 48s\tremaining: 36.5s\n",
      "411:\tlearn: 2.2801960\ttotal: 2m 49s\tremaining: 36.1s\n",
      "412:\tlearn: 2.2801230\ttotal: 2m 49s\tremaining: 35.7s\n",
      "413:\tlearn: 2.2800477\ttotal: 2m 49s\tremaining: 35.3s\n",
      "414:\tlearn: 2.2799900\ttotal: 2m 50s\tremaining: 34.9s\n",
      "415:\tlearn: 2.2799061\ttotal: 2m 50s\tremaining: 34.5s\n",
      "416:\tlearn: 2.2798580\ttotal: 2m 51s\tremaining: 34.1s\n",
      "417:\tlearn: 2.2798036\ttotal: 2m 51s\tremaining: 33.7s\n",
      "418:\tlearn: 2.2796958\ttotal: 2m 52s\tremaining: 33.3s\n",
      "419:\tlearn: 2.2796241\ttotal: 2m 52s\tremaining: 32.9s\n",
      "420:\tlearn: 2.2795350\ttotal: 2m 52s\tremaining: 32.4s\n",
      "421:\tlearn: 2.2794888\ttotal: 2m 53s\tremaining: 32s\n",
      "422:\tlearn: 2.2794021\ttotal: 2m 53s\tremaining: 31.6s\n",
      "423:\tlearn: 2.2793393\ttotal: 2m 54s\tremaining: 31.2s\n",
      "424:\tlearn: 2.2792087\ttotal: 2m 54s\tremaining: 30.8s\n",
      "425:\tlearn: 2.2791512\ttotal: 2m 55s\tremaining: 30.4s\n",
      "426:\tlearn: 2.2790862\ttotal: 2m 55s\tremaining: 30s\n",
      "427:\tlearn: 2.2790470\ttotal: 2m 55s\tremaining: 29.6s\n",
      "428:\tlearn: 2.2789971\ttotal: 2m 56s\tremaining: 29.2s\n",
      "429:\tlearn: 2.2789194\ttotal: 2m 56s\tremaining: 28.8s\n",
      "430:\tlearn: 2.2788695\ttotal: 2m 57s\tremaining: 28.3s\n",
      "431:\tlearn: 2.2787989\ttotal: 2m 57s\tremaining: 27.9s\n",
      "432:\tlearn: 2.2787895\ttotal: 2m 57s\tremaining: 27.5s\n",
      "433:\tlearn: 2.2787487\ttotal: 2m 58s\tremaining: 27.1s\n",
      "434:\tlearn: 2.2787169\ttotal: 2m 58s\tremaining: 26.7s\n",
      "435:\tlearn: 2.2786743\ttotal: 2m 59s\tremaining: 26.3s\n",
      "436:\tlearn: 2.2786365\ttotal: 2m 59s\tremaining: 25.9s\n",
      "437:\tlearn: 2.2786133\ttotal: 2m 59s\tremaining: 25.5s\n",
      "438:\tlearn: 2.2785614\ttotal: 3m\tremaining: 25s\n",
      "439:\tlearn: 2.2784459\ttotal: 3m\tremaining: 24.6s\n",
      "440:\tlearn: 2.2783138\ttotal: 3m 1s\tremaining: 24.2s\n",
      "441:\tlearn: 2.2782413\ttotal: 3m 1s\tremaining: 23.8s\n",
      "442:\tlearn: 2.2781909\ttotal: 3m 1s\tremaining: 23.4s\n",
      "443:\tlearn: 2.2781658\ttotal: 3m 2s\tremaining: 23s\n",
      "444:\tlearn: 2.2781323\ttotal: 3m 2s\tremaining: 22.6s\n",
      "445:\tlearn: 2.2780556\ttotal: 3m 3s\tremaining: 22.2s\n",
      "446:\tlearn: 2.2780167\ttotal: 3m 3s\tremaining: 21.8s\n",
      "447:\tlearn: 2.2779083\ttotal: 3m 3s\tremaining: 21.4s\n",
      "448:\tlearn: 2.2777741\ttotal: 3m 4s\tremaining: 20.9s\n",
      "449:\tlearn: 2.2777056\ttotal: 3m 4s\tremaining: 20.5s\n",
      "450:\tlearn: 2.2776152\ttotal: 3m 5s\tremaining: 20.1s\n",
      "451:\tlearn: 2.2775491\ttotal: 3m 5s\tremaining: 19.7s\n",
      "452:\tlearn: 2.2775101\ttotal: 3m 5s\tremaining: 19.3s\n",
      "453:\tlearn: 2.2774907\ttotal: 3m 6s\tremaining: 18.9s\n",
      "454:\tlearn: 2.2774379\ttotal: 3m 6s\tremaining: 18.5s\n",
      "455:\tlearn: 2.2773822\ttotal: 3m 7s\tremaining: 18.1s\n",
      "456:\tlearn: 2.2773349\ttotal: 3m 7s\tremaining: 17.6s\n",
      "457:\tlearn: 2.2772941\ttotal: 3m 7s\tremaining: 17.2s\n",
      "458:\tlearn: 2.2772720\ttotal: 3m 8s\tremaining: 16.8s\n",
      "459:\tlearn: 2.2772481\ttotal: 3m 8s\tremaining: 16.4s\n",
      "460:\tlearn: 2.2772376\ttotal: 3m 9s\tremaining: 16s\n",
      "461:\tlearn: 2.2772039\ttotal: 3m 9s\tremaining: 15.6s\n",
      "462:\tlearn: 2.2771115\ttotal: 3m 9s\tremaining: 15.2s\n",
      "463:\tlearn: 2.2770482\ttotal: 3m 10s\tremaining: 14.8s\n",
      "464:\tlearn: 2.2770086\ttotal: 3m 10s\tremaining: 14.3s\n",
      "465:\tlearn: 2.2769578\ttotal: 3m 10s\tremaining: 13.9s\n",
      "466:\tlearn: 2.2769319\ttotal: 3m 11s\tremaining: 13.5s\n",
      "467:\tlearn: 2.2768755\ttotal: 3m 11s\tremaining: 13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468:\tlearn: 2.2768254\ttotal: 3m 12s\tremaining: 12.7s\n",
      "469:\tlearn: 2.2767845\ttotal: 3m 12s\tremaining: 12.3s\n",
      "470:\tlearn: 2.2767290\ttotal: 3m 12s\tremaining: 11.9s\n",
      "471:\tlearn: 2.2766694\ttotal: 3m 13s\tremaining: 11.5s\n",
      "472:\tlearn: 2.2765776\ttotal: 3m 13s\tremaining: 11.1s\n",
      "473:\tlearn: 2.2764874\ttotal: 3m 14s\tremaining: 10.7s\n",
      "474:\tlearn: 2.2764333\ttotal: 3m 14s\tremaining: 10.2s\n",
      "475:\tlearn: 2.2763588\ttotal: 3m 15s\tremaining: 9.84s\n",
      "476:\tlearn: 2.2763030\ttotal: 3m 15s\tremaining: 9.43s\n",
      "477:\tlearn: 2.2762673\ttotal: 3m 16s\tremaining: 9.02s\n",
      "478:\tlearn: 2.2762378\ttotal: 3m 16s\tremaining: 8.61s\n",
      "479:\tlearn: 2.2762005\ttotal: 3m 16s\tremaining: 8.2s\n",
      "480:\tlearn: 2.2761716\ttotal: 3m 17s\tremaining: 7.79s\n",
      "481:\tlearn: 2.2761309\ttotal: 3m 17s\tremaining: 7.39s\n",
      "482:\tlearn: 2.2760962\ttotal: 3m 18s\tremaining: 6.98s\n",
      "483:\tlearn: 2.2760314\ttotal: 3m 18s\tremaining: 6.57s\n",
      "484:\tlearn: 2.2760012\ttotal: 3m 19s\tremaining: 6.16s\n",
      "485:\tlearn: 2.2759814\ttotal: 3m 19s\tremaining: 5.75s\n",
      "486:\tlearn: 2.2759266\ttotal: 3m 20s\tremaining: 5.34s\n",
      "487:\tlearn: 2.2759108\ttotal: 3m 20s\tremaining: 4.93s\n",
      "488:\tlearn: 2.2758657\ttotal: 3m 21s\tremaining: 4.52s\n",
      "489:\tlearn: 2.2758084\ttotal: 3m 21s\tremaining: 4.11s\n",
      "490:\tlearn: 2.2757798\ttotal: 3m 21s\tremaining: 3.7s\n",
      "491:\tlearn: 2.2757340\ttotal: 3m 22s\tremaining: 3.29s\n",
      "492:\tlearn: 2.2756886\ttotal: 3m 22s\tremaining: 2.88s\n",
      "493:\tlearn: 2.2756750\ttotal: 3m 23s\tremaining: 2.47s\n",
      "494:\tlearn: 2.2756228\ttotal: 3m 23s\tremaining: 2.06s\n",
      "495:\tlearn: 2.2756066\ttotal: 3m 23s\tremaining: 1.64s\n",
      "496:\tlearn: 2.2755808\ttotal: 3m 24s\tremaining: 1.23s\n",
      "497:\tlearn: 2.2755168\ttotal: 3m 24s\tremaining: 822ms\n",
      "498:\tlearn: 2.2754263\ttotal: 3m 25s\tremaining: 411ms\n",
      "499:\tlearn: 2.2753904\ttotal: 3m 25s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2af13ec4650>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pool_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sales: [1.40992445]\n"
     ]
    }
   ],
   "source": [
    "# Example test data (replace with your actual test data)\n",
    "test_data = pd.DataFrame({\n",
    "    'Item code': ['ANTIBIOTIC_218'],\n",
    "    'Category': ['ANTIBIOTIC'],\n",
    "    'State': ['TN'],\n",
    "    'Date': ['22-02-2022']\n",
    "})\n",
    "\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'], format='%d-%m-%Y')\n",
    "test_data['Item code'] = label_encoder.fit_transform(test_data['Item code'])\n",
    "test_data['Category'] = label_encoder.fit_transform(test_data['Category'])\n",
    "test_data['State'] = label_encoder.fit_transform(test_data['State'])\n",
    "# Fit and transform the 'Item code' column\n",
    "#test_pool_encoded = Pool(data=test_data.drop(columns=['Sales']), label=test_data['Sales'])\n",
    "\n",
    "# Create a Pool object for test data\n",
    "#test_pool = Pool(data=test_data.drop(columns=['Sales']))\n",
    "\n",
    "# Predict sales\n",
    "preds = model.predict(test_data)\n",
    "print(\"Predicted sales:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item code</th>\n",
       "      <th>Category</th>\n",
       "      <th>State</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>ANTIDIABETIC_006</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>30-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>ANTIDIABETIC_006</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>UP</td>\n",
       "      <td>30-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>ANTIDIABETIC_006</td>\n",
       "      <td>ANTIDIABETIC</td>\n",
       "      <td>TN</td>\n",
       "      <td>30-01-2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Item code      Category State        Date  Sales\n",
       "3497  ANTIDIABETIC_006  ANTIDIABETIC    MH  30-01-2017      0\n",
       "4661  ANTIDIABETIC_006  ANTIDIABETIC    UP  30-01-2017      0\n",
       "5825  ANTIDIABETIC_006  ANTIDIABETIC    TN  30-01-2017      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_long[(data_long['Date']=='30-01-2017') & (data_long['Item code']=='ANTIDIABETIC_006')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llNoajmPPsAT"
   },
   "source": [
    "From dataset, we can observe that except `id` column, all the other columns play a significant role in final sales of videogames. So it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbF51P4J0i5J"
   },
   "outputs": [],
   "source": [
    "y_true= pd.DataFrame(data=test[target], columns=['Sales'])\n",
    "test_temp = test.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ENT4KaktXvF"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=train_data['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Dlwy84mtdahl",
    "outputId": "41a7649a-d439-4acb-c780-fdae8d4f9444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27539043455582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 45.94%\n"
     ]
    }
   ],
   "source": [
    "def wmape(actual, forecast):\n",
    "    \"\"\"\n",
    "    Calculates the Weighted Mean Absolute Percentage Error (WMAPE).\n",
    "    \n",
    "    Parameters:\n",
    "    actual (array-like): Array of actual sales values.\n",
    "    forecast (array-like): Array of forecasted sales values.\n",
    "    \n",
    "    Returns:\n",
    "    float: WMAPE value.\n",
    "    \"\"\"\n",
    "    weights = actual.replace(0, 1)  # Replace zeros with ones to avoid division by zero\n",
    "    absolute_percentage_errors = abs((actual - forecast) / weights)\n",
    "    wmape = sum(absolute_percentage_errors) / sum(weights)\n",
    "    return wmape * 100  # Convert to percentage\n",
    "\n",
    "# Assuming you have actual sales values and forecasted sales values\n",
    "actual_sales = y_test  # Actual sales values\n",
    "forecasted_sales = y_pred  # Forecasted sales values\n",
    "\n",
    "# Calculate WMAPE\n",
    "wmape_value = wmape(actual_sales, forecasted_sales)\n",
    "print(f\"Weighted Mean Absolute Percentage Error (WMAPE): {wmape_value:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "train_data2['Date'] = pd.to_datetime(train_data['Date'], format='%d%m%Y')\n",
    "train_data2['Year'] = train_data2['Date'].dt.year\n",
    "train_data2['Month'] = train_data2['Date'].dt.month\n",
    "train_data2['Day'] = train_data2['Date'].dt.day\n",
    "train_data2['Item code'] = label_encoder.fit_transform(train_data['Item code'])\n",
    "train_data2['Category'] = label_encoder.fit_transform(train_data['Category'])\n",
    "train_data2['State'] = label_encoder.fit_transform(train_data['State'])\n",
    "train_data2=train_data2.drop(columns=['Date'])\n",
    "# Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf=xgb_model.fit(train_data2, train_data['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data2, train_data['Sales'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=90, learning_rate=0.01,max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf\u001b[38;5;241m=\u001b[39mxgb_model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[38;5;241m.\u001b[39mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf=xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 45.49%\n"
     ]
    }
   ],
   "source": [
    "def wmape(actual, forecast):\n",
    "    \"\"\"\n",
    "    Calculates the Weighted Mean Absolute Percentage Error (WMAPE).\n",
    "    \n",
    "    Parameters:\n",
    "    actual (array-like): Array of actual sales values.\n",
    "    forecast (array-like): Array of forecasted sales values.\n",
    "    \n",
    "    Returns:\n",
    "    float: WMAPE value.\n",
    "    \"\"\"\n",
    "    weights = actual.replace(0, 1)  # Replace zeros with ones to avoid division by zero\n",
    "    absolute_percentage_errors = abs((actual - forecast) / weights)\n",
    "    wmape = sum(absolute_percentage_errors) / sum(weights)\n",
    "    return wmape * 100  # Convert to percentage\n",
    "\n",
    "\n",
    "y_pred2=clf.predict(X_test)\n",
    "# Assuming you have actual sales values and forecasted sales values\n",
    "actual_sales = y_test  # Actual sales values\n",
    "forecasted_sales = y_pred2  # Forecasted sales values\n",
    "\n",
    "# Calculate WMAPE\n",
    "wmape_value = wmape(actual_sales, forecasted_sales)\n",
    "print(f\"Weighted Mean Absolute Percentage Error (WMAPE): {wmape_value:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(3, 11)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 200, 300, 400, 500]),\n",
    "    # Add other hyperparameters as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function (mean squared error in this case)\n",
    "def objective(params):\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Optimize hyperparameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_params \u001b[38;5;241m=\u001b[39m fmin(fn\u001b[38;5;241m=\u001b[39mobjective, space\u001b[38;5;241m=\u001b[39mspace, algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[38;5;241m.\u001b[39mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_evals \u001b[38;5;241m-\u001b[39m n_done, block_until_done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[169], line 4\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(params):\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m----> 4\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[38;5;241m.\u001b[39mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimize hyperparameters\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, verbose=0)\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'y_pred2': y_pred2, 'y_test': y_test} \n",
    "df2=pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred2</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463687</th>\n",
       "      <td>1.105512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463688</th>\n",
       "      <td>1.105512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463689</th>\n",
       "      <td>1.105512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463690</th>\n",
       "      <td>3.636479</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463691</th>\n",
       "      <td>3.636479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6463692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_pred2  y_test\n",
       "0        0.769793       0\n",
       "1        0.769793       0\n",
       "2        0.905062       0\n",
       "3        0.905062       0\n",
       "4        0.905062       0\n",
       "...           ...     ...\n",
       "6463687  1.105512       1\n",
       "6463688  1.105512       1\n",
       "6463689  1.105512       0\n",
       "6463690  3.636479       7\n",
       "6463691  3.636479       1\n",
       "\n",
       "[6463692 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-E1rjszrlOwF"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0amJNtMs0ib"
   },
   "outputs": [],
   "source": [
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjtvoAYIlaNm"
   },
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "sYRDWTGcltJJ",
    "outputId": "7cd753e4-b53b-4c49-c887-18b6d64bfbe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90177037])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(test_temp[features].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrKHOZEysqC_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+HEbZBh8lru2jUr++ZN59",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Video_Game_Sales_prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "023558eecb034d5b94686fc3c455b71a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Export report to file: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2907b3e43095404b8dd4d5126c620408",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a540de917a5447fc9fa29d7929b38ecd",
      "value": 1
     }
    },
    "1bcfade3e9824c3e939715e1de33c32a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2907b3e43095404b8dd4d5126c620408": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a27da1d62f14bbb9f14482822c20004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84fde40e712a4718941823446f9c7c05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bcfade3e9824c3e939715e1de33c32a",
      "placeholder": "​",
      "style": "IPY_MODEL_7a27da1d62f14bbb9f14482822c20004",
      "value": " 1/1 [00:02&lt;00:00,  2.31s/it]"
     }
    },
    "a105a2f13ce3459ab2ce65e88d18b6e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a540de917a5447fc9fa29d7929b38ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d51b081ce5814c79b31be05f9ca6128f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_023558eecb034d5b94686fc3c455b71a",
       "IPY_MODEL_84fde40e712a4718941823446f9c7c05"
      ],
      "layout": "IPY_MODEL_a105a2f13ce3459ab2ce65e88d18b6e6"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
